<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>大数据之 MapReduce (三) | Simon 的书柜</title><meta name="author" content="Simon"><meta name="copyright" content="Simon"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="大数据课程之 MapReduce (三)概述定义MapReduce 是一个分布式运算的编程框架，是用户开发“基于 Hadoop 的数据分析应用”的核心框架 MapReduce 的核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上  优缺点优点  易于编程，用户只关心业务逻辑 良好的扩展性，可动态增加服务器 高容错性，任何一台机器挂掉">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据之 MapReduce (三)">
<meta property="og:url" content="http://yoursite.com/2022/09/17/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%20MapReduce%20(%E4%B8%89)/index.html">
<meta property="og:site_name" content="Simon 的书柜">
<meta property="og:description" content="大数据课程之 MapReduce (三)概述定义MapReduce 是一个分布式运算的编程框架，是用户开发“基于 Hadoop 的数据分析应用”的核心框架 MapReduce 的核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上  优缺点优点  易于编程，用户只关心业务逻辑 良好的扩展性，可动态增加服务器 高容错性，任何一台机器挂掉">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BMapReduce%28%E4%B8%89%29/F100031816.jpg">
<meta property="article:published_time" content="2022-09-17T11:16:08.000Z">
<meta property="article:modified_time" content="2024-06-08T04:13:07.150Z">
<meta property="article:author" content="Simon">
<meta property="article:tag" content="大数据">
<meta property="article:tag" content="MapReduce">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BMapReduce%28%E4%B8%89%29/F100031816.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://yoursite.com/2022/09/17/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%20MapReduce%20(%E4%B8%89)/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '大数据之 MapReduce (三)',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-06-08 12:13:07'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E8%83%8C%E6%99%AF%E5%9B%BE/v2-bd12bc8dfb61abe313ad48b907c5da94_720w.webp" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">41</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">32</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BMapReduce%28%E4%B8%89%29/F100031816.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Simon 的书柜"><span class="site-name">Simon 的书柜</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">大数据之 MapReduce (三)</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-09-17T11:16:08.000Z" title="发表于 2022-09-17 19:16:08">2022-09-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-06-08T04:13:07.150Z" title="更新于 2024-06-08 12:13:07">2024-06-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="大数据之 MapReduce (三)"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="大数据课程之-MapReduce-三"><a href="#大数据课程之-MapReduce-三" class="headerlink" title="大数据课程之 MapReduce (三)"></a>大数据课程之 MapReduce (三)</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>MapReduce 是一个分布式运算的编程框架，是用户开发“基于 Hadoop 的数据分析应用”的核心框架</p>
<p>MapReduce 的核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上</p>
<hr>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>优点</p>
<ol>
<li>易于编程，用户只关心业务逻辑</li>
<li>良好的扩展性，可动态增加服务器</li>
<li>高容错性，任何一台机器挂掉，可以将任务转移到其它节点</li>
<li>适合海量数据计算</li>
</ol>
<p>缺点</p>
<ol>
<li>不擅长实时计算</li>
<li>不擅长流式计算</li>
<li>不擅长 DAG 有向无环图计算</li>
</ol>
<hr>
<h3 id="核心思想"><a href="#核心思想" class="headerlink" title="核心思想"></a>核心思想</h3><p><img src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BMapReduce%28%E4%B8%89%29/image-20220516232151563.png" alt="image-20220516232151563"></p>
<p>分布式的运算程序往往需要分成至少 2 个阶段，第一个阶段的  MapTask 并发实例，完全并行运行，互不相干，第二个阶段的 ReduceTask 并发实例互不相干，但是他们的数据依赖于上一个阶段 的所有 MapTask 并发实例的输出</p>
<p>MapReduce 编程模型只能包含一个 Map 阶段和一个 Reduce 阶段，如果用户的业 务逻辑非常复杂，那就只能多个 MapReduce 程序，串行运行</p>
<hr>
<h3 id="MapReduce-进程"><a href="#MapReduce-进程" class="headerlink" title="MapReduce 进程"></a>MapReduce 进程</h3><p>一个完整的 MapReduce 程序在分布式运行时有三类实例进程：</p>
<ol>
<li>MrAppMaster：负责整个程序的过程调度及状态协调</li>
<li>MapTask：负责 Map 阶段的整个数据处理流程</li>
<li>ReduceTask：负责 Reduce 阶段的整个数据处理流程</li>
</ol>
<hr>
<h3 id="常用序列化类型"><a href="#常用序列化类型" class="headerlink" title="常用序列化类型"></a>常用序列化类型</h3><p><img src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BMapReduce%28%E4%B8%89%29/zo16gfucat.png" alt="preload"></p>
<p>除了 Text  类型的其他类型都是在Java类型的后面加了 Writable</p>
<hr>
<h3 id="MapReduce-编程规范"><a href="#MapReduce-编程规范" class="headerlink" title="MapReduce 编程规范"></a>MapReduce 编程规范</h3><p>用户编写的程序分成三个部分：Mapper、Reducer 和 Driver</p>
<ul>
<li><p>Mapper 阶段</p>
<ol>
<li>用户自定义的 Mapper 要继承自己的父类 </li>
<li>Mapper 的输入数据是 KV 对（K：偏移量，V：对应的内容）的形式(KV 的类型可自定义) </li>
<li>Mapper 中的业务逻辑写在map() 方法中</li>
<li>Mapper 的输出数据是 KV 对的形式(KV 的类型可自定义)</li>
<li>map() 方法( MapTask 进程）对每一个&lt;K,V&gt;调用一次</li>
</ol>
</li>
<li><p>Reducer 阶段</p>
<ol>
<li>用户自定义的 Reducer 要继承自己的父类</li>
<li>Reducer 的输入数据类型对应 Mapper 的输出数据类型，也是 KV</li>
<li>Reducer 的业务逻辑写在 reduce() 方法中</li>
<li>ReduceTask 进程对每一组相同 k 的 &lt;k,v&gt; 组调用一次 reduce() 方法</li>
</ol>
</li>
<li><p>Driver 阶段</p>
<p>相当于 YARN 集群的客户端，用于提交我们整个程序到 YARN 集群，提交的是封装了 MapReduce 程序相关运行参数的 job 对象</p>
</li>
</ul>
<hr>
<h3 id="WordCount-案例详解"><a href="#WordCount-案例详解" class="headerlink" title="WordCount 案例详解"></a>WordCount 案例详解</h3><p>根据 MapReduce 官方案例，对文本文件中按单词首字母分组，计算出每个分组的数量，比如以下文本文件</p>
<p>Hello World</p>
<p>This</p>
<p>is</p>
<p>Map Reduce</p>
<p>按照 MapReduce 编码规范，我们需要写 3 个类分别实现 Mapper、Reducer 和 Driver 的方法</p>
<p>Mapper 实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Mapper 类有 4 个泛型参数，分别是 map 阶段 2 个输入内容和 2 个输出内容</span></span><br><span class="line"><span class="comment"> * 输入内容</span></span><br><span class="line"><span class="comment"> * LongWritable : 每行文本的偏移量</span></span><br><span class="line"><span class="comment"> * Text : 每行文本内容</span></span><br><span class="line"><span class="comment"> * 输出内容</span></span><br><span class="line"><span class="comment"> * Text : 统计出来的单词结果</span></span><br><span class="line"><span class="comment"> * IntWriteable : 该单词出现的次数</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">IntWritable</span> <span class="variable">one</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Text</span> <span class="variable">text</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 对文本结果进行 Map 统计，只需要入参，将统计的中间结果写入 context，供 Reduce 流程使用</span></span><br><span class="line"><span class="comment">     * 对于 Map 来说，每次读取到一行文本内容，就会调用一次 map 方法</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 将 Text 转为 String，便于更多的 api 操作</span></span><br><span class="line">        String[] words = value.toString().split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">            text.set(word);</span><br><span class="line">            <span class="comment">// 将统计的结果记入 context，key 为单词内容，value 为出现的次数，即 1</span></span><br><span class="line">            context.write(text, one);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>Reducer 实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 与 Mapper 相同，Reducer 也有 4 个泛型参数，分别书输入的 key value 和输出的 key value</span></span><br><span class="line"><span class="comment"> * 而输入的 key value 则是 map 阶段的输出结果</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * reduce 阶段会一次性读到所有 key 相同的输入结果，即多个键值对，读取到一次结果则调用一个 reduce 方法</span></span><br><span class="line"><span class="comment">     * 这些键值对的 key 相同，因此 reduce 方法中只有一个 key，而 value 是一个可迭代的结果</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 统计当前 key 出现的次数</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">            sum += value.get();</span><br><span class="line">        &#125;</span><br><span class="line">        result.set(sum);</span><br><span class="line">        <span class="comment">// 将统计结果写入 context</span></span><br><span class="line">        context.write(key, result);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>Driver 实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 创建一个 job</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration);</span><br><span class="line">        <span class="comment">// 设置 jar 包路径</span></span><br><span class="line">        job.setJarByClass(WordCountDriver.class);</span><br><span class="line">        <span class="comment">// 设置 map 类和 reduce 类</span></span><br><span class="line">        job.setMapperClass(WordCountMapper.class);</span><br><span class="line">        job.setReducerClass(WordCountReducer.class);</span><br><span class="line">        <span class="comment">// 设置输出的 key 和 value 的类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line">        <span class="comment">// 设置读取文件的路径和输出结果的文件路径</span></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;读取文件的路径&quot;</span>));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;输出文件的路径&quot;</span>));</span><br><span class="line">        <span class="comment">// 执行 job, 传入值表示是否监控并打印 job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        <span class="comment">// 退出系统</span></span><br><span class="line">        System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="序列化"><a href="#序列化" class="headerlink" title="序列化"></a>序列化</h2><h3 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h3><p>序列化就是把内存中的对象，转换成字节序列（或其他数据传输协议）以便于存储到磁盘（持久化）和网络传输</p>
<p>反序列化就是将受到字节序列（或其他数据传输协议）或者是磁盘的持久化数据，转换成内存中的对象</p>
<hr>
<h3 id="自定义-bean-对象实现-Writeable-接口"><a href="#自定义-bean-对象实现-Writeable-接口" class="headerlink" title="自定义 bean 对象实现 Writeable 接口"></a>自定义 bean 对象实现 Writeable 接口</h3><p>在企业开发中往往常用的基本序列化类型不能满足所有需求，比如在 Hadoop 框架内部传递一个bean对象，那么该对象就需要实现序列化接口</p>
<p>具体实现 bean 对象序列化步骤如下 7 步</p>
<ol>
<li>必须实现 Writable 接口</li>
<li>反序列化时，需要反射调用空参构造函数，所以必须有空参构造</li>
<li>重写序列化方法</li>
<li>重写反序列化方法</li>
<li>注意反序列化的顺序和序列化的顺序完全一致</li>
<li>要想把结果显示在文件中，需要重写 toString()，可用”\t”分开，方便后续用</li>
<li>如果需要将自定义的 bean 放在 key 中传输，则还需要实现 Comparable 接口，因为 MapReduce 框中的 Shuffle 过程要求对 key 必须能排序</li>
</ol>
<hr>
<h2 id="框架原理"><a href="#框架原理" class="headerlink" title="框架原理"></a>框架原理</h2><h3 id="切片与-MapTask-并行度决定机制"><a href="#切片与-MapTask-并行度决定机制" class="headerlink" title="切片与 MapTask 并行度决定机制"></a>切片与 MapTask 并行度决定机制</h3><p>MapTask的并行度决定Map阶段的任务处理并发度，进而影响到整个 Job 的处理速度</p>
<p>数据块：Block 是 HDFS 物理上把数据分成一块一块</p>
<p>数据切片：数据切片只是在逻辑上对输入进行分片，并不会在磁盘上将其切分成片进行存储</p>
<p>如果切片大小与数据块大小不一致的话，就可能造成一个切片需要去不同的 Block 中读取数据或者一个 Block 被划分成多个数据切片，因此最合理的方式就是切片大小等于 Block 大小</p>
<p><img src="https://img-blog.csdnimg.cn/20210602185331161.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzU5NzIwOA==,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p>
<hr>
<h3 id="FileInputFormat-切片机制"><a href="#FileInputFormat-切片机制" class="headerlink" title="FileInputFormat 切片机制"></a>FileInputFormat 切片机制</h3><p>切片机制：</p>
<ol>
<li>简单的按照文件的内容长度进行切片</li>
<li>切片大小，默认等于 Block 大小</li>
<li>切片时不考虑数据集整体，而是逐个针对每一个文件进行单独切片</li>
</ol>
<p>源码中计算切片大小的相关参数</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// mapreduce.input.fileinputformat.split.minsize = 1 默认值为 1</span></span><br><span class="line"><span class="comment">// mapreduce.input.fileinputformat.split.maxsize = Long.MAXValue 默认值为 Long.MAXValue</span></span><br><span class="line">Math.max(minSize, Math.min(maxSize, blockSize));</span><br></pre></td></tr></table></figure>

<p>获取切片信息的相关 API</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 获取切片信息的文件名称</span></span><br><span class="line"><span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> inputSplit.getPath().getName();</span><br><span class="line"><span class="comment">// 根据文件类型获取切片信息</span></span><br><span class="line"><span class="type">FileSplit</span> <span class="variable">inputSplit</span> <span class="operator">=</span> (FileSplit)context.getInputSplit();</span><br></pre></td></tr></table></figure>



<hr>
<h3 id="MapReduce-工作流程"><a href="#MapReduce-工作流程" class="headerlink" title="MapReduce 工作流程"></a>MapReduce 工作流程</h3><p><img src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BMapReduce%28%E4%B8%89%29/image-20220523000115325.png" alt="image-20220523000115325"></p>
<ol>
<li><p>分片、格式化数据源</p>
<p>输入 Map 阶段的数据源，必须经过分片和格式化操作</p>
<p>分片操作：指的是将源文件划分为大小相等的小数据块( Hadoop 2.x 中默认 128MB )，也就是分片，Hadoop 会为每一个分片构建一个 Map 任务，并由该任务运行自定义的 map() 函数，从而处理分片里的每一条记录</p>
<p>格式化操作：将划分好的分片格式化为键值对&lt;key,value&gt;形式的数据，其中， key 代表偏移量， value 代表每一行内容</p>
</li>
<li><p>执行 MapTask</p>
<p>每个 Map 任务都有一个内存缓冲区(缓冲区大小 100MB )，输入的分片数据经过 Map 任务处理后的中间结果会写入内存缓冲区中</p>
<p>如果写人的数据达到内存缓冲的阈值( 80MB )，会启动一个线程将内存中的溢出数据写入磁盘，同时不影响 Map 中间结果继续写入缓冲区</p>
<p>在溢写过程中， MapReduce 框架会对 key 进行排序，如果中间结果比较大，会形成多个溢写文件，最后的缓冲区数据也会全部溢写入磁盘形成一个溢写文件，如果是多个溢写文件，则最后合并所有的溢写文件为一个文件</p>
</li>
<li><p>执行 Shuffle 过程</p>
<p>MapReduce 工作过程中， Map 阶段处理的数据如何传递给 Reduce 阶段，这是 MapReduce 框架中关键的一个过程，这个过程叫作 Shuffle</p>
<p>Shuffle 会将 MapTask 输出的处理结果数据分发给 ReduceTask ，并在分发的过程中，对数据按 key 进行分区和排序</p>
</li>
<li><p>执行 ReduceTask</p>
<p>输入 ReduceTask 的数据流是&lt;key, {value list}&gt;形式，用户可以自定义 reduce()方法进行逻辑处理，最终以&lt;key, value&gt;的形式输出</p>
</li>
<li><p>写入文件</p>
<p>MapReduce 框架会自动把 ReduceTask 生成的&lt;key, value&gt;传入 OutputFormat 的 write 方法，实现文件的写入操作</p>
</li>
</ol>
<hr>
<h2 id="Shuffle-机制"><a href="#Shuffle-机制" class="headerlink" title="Shuffle 机制"></a>Shuffle 机制</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p> Mapreduce 确保每个 reducer 的输入都是按键排序的。系统执行排序的过程(即将 map 输出作为输入传给 reducer)称为 shuffle</p>
<hr>
<h3 id="详细流程"><a href="#详细流程" class="headerlink" title="详细流程"></a>详细流程</h3><ol>
<li>mapTask 收集我们 map() 方法输出的 kv 对，放在内存缓冲区 kvbuffer（环形缓冲区：内存中的一种首尾相连的数据结构，kvbuffer 包含数据区和索引区）中，在存数据的时候，会调用 partitioner 进行分区编号的计算，并存入元数据中</li>
<li>当内存缓冲区的数据达到 100M*0.8 时，就会开始溢写到本地磁盘文件 file.out，可能会溢出多次，则会有多个文件，相应的缓冲区中的索引区数据溢出为磁盘索引文件 file.out.index</li>
<li>在溢写前，会先根据分区编号排序，相同的分区的数据，排在一起，再根据 map 的 key 排序（快排）</li>
<li>多个溢写文件会被合并成大的溢出文件（归并排序）</li>
<li>在数据量大的时.候，可以对 maptask 结果启用压缩，将 mapreduce.map.ouput.compress 设为 true，并使用 mapreduce.map.output.compress.codec 设置使用的压缩算法，可以提高数据传输到 reduce 端的效率</li>
<li>reduceTask 根据自己的分区号，去各个 mapTask 机器上取相应的结果分区数据</li>
<li>reduceTask 会取到同一个分区的来自不同 mapTask 的结果文件，reduceTask 会将这些文件再进行合并（归并排序）</li>
<li>合并成大文件后，shuffle 的过程也就结束了，后面进入 reduceTask 的逻辑运算过程（从文件中取出一个一个的键值对 group，调用用户自定义的 reduce(）方法）</li>
</ol>
<hr>
<h3 id="默认分区"><a href="#默认分区" class="headerlink" title="默认分区"></a>默认分区</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HashPartitioner</span>&lt;K, V&gt; <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;K, V&gt; &#123;</span><br><span class="line">	<span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(K key, V value, <span class="type">int</span> numReduceTask)</span> &#123;</span><br><span class="line">		<span class="keyword">return</span> (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTask;</span><br><span class="line">	&#125;</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<p>默认分区是根据 key 的 hashCode对reduceTasks 个数取模得到的。用户没法控制哪个 key 存储到哪个分区</p>
<hr>
<h3 id="自定义分区"><a href="#自定义分区" class="headerlink" title="自定义分区"></a>自定义分区</h3><p>如果想要根据自己的需求生成不同的分区文件，那么就需要自定义分区方法而不是使用默认的分区方法。比如想要将不同开头的手机号放进不同的分区文件中，通过如下步骤实现即可</p>
<ol>
<li><p>自定义类继承 Partitioner，重写 getPartition() 方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;Text, FlowBean&gt; &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(K key, FlowBean value, <span class="type">int</span> numReduceTask)</span> &#123;</span><br><span class="line">        <span class="comment">// 获取电话号码前三位</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">preNum</span> <span class="operator">=</span> key.toString().substring(<span class="number">0</span>, <span class="number">3</span>);</span><br><span class="line">        <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> <span class="number">4</span>;</span><br><span class="line">        <span class="comment">// 根据号码的不同放入不同的分区文件</span></span><br><span class="line">        <span class="keyword">switch</span> (preNum) &#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;136&quot;</span>:</span><br><span class="line">                partition = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;137&quot;</span>:</span><br><span class="line">                partition = <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;138&quot;</span>:</span><br><span class="line">                partition = <span class="number">2</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&quot;139&quot;</span>:</span><br><span class="line">                partition = <span class="number">3</span>;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>:</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> partition;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 job 驱动中，设置自定义 partitioner</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setPartitionrtClass(ProvincePartitioner.class);</span><br></pre></td></tr></table></figure>
</li>
<li><p>自定义 partition 后，要根据自定义 partitioner 的逻辑设置相应数量的 reduce task</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setNumReduceTask(<span class="number">5</span>);</span><br></pre></td></tr></table></figure></li>
</ol>
<p>需要注意的是：</p>
<ol>
<li>如果 reduceTask 的数量 &gt; getPartition 的结果数，则会多产生几个空的输出文件 part-r-000xx</li>
<li>如果1 &lt; reduceTask 的数量 &lt; getPartition 的结果数，则有一部分分区数据无处安放，会产生异常</li>
<li>如果 reduceTask 的数量 &#x3D; 1，则不管 mapTask 端输出多少个分区文件，最终结果都交给这一个 reduceTask，最终也就只会产生一个结果文件 part-r-00000</li>
</ol>
<hr>
<h2 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h2><h3 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h3><p>排序是 MapReduce 中非常重要的操作之一，MapTask 和 ReduceTask 都会对数据按照 key 进行排序。该操作是默认行为。任何 MapReduce 程序中数据均会被排序，而不看逻辑是否需要</p>
<p>在 MapReduce 的 shuffle 阶段共有三次排序，分别是：</p>
<ol>
<li>Map 的溢写阶段：根据分区及 key 进行快速排序</li>
<li>Map 合并溢写文件阶段：将同一个分区的多个溢写文件经过多轮归并排序最终合并为一个文件</li>
<li>Reduce 输入阶段：将同一个分区，不同 map task 的数据文件进行归并排序</li>
</ol>
<hr>
<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><ul>
<li><p>部分排序</p>
<p>MapReduce 根据输入记录的键对数据集排序，保证输出的每个文件内部有序</p>
</li>
<li><p>全排序</p>
<p>最终输出结果只要一个文件，且文件内部有序。实现方式是只设置一个 ReduceTask。但该方法在处理大型文件时效率极低，因为一台机器处理所有文件，完全丧失了 MapReduce 所提供的并行架构</p>
</li>
<li><p>辅助排序(GroupingComparator分组)</p>
<p>在 Reduce 端对 key 进行分组。应用于：在接收的 key 为 bean 对象时，想让一个或几个字段相同(全部字段比较不相同)的 key 进入到同一个 reduce 方法时，可以采用分组排序</p>
</li>
<li><p>二次排序</p>
<p>在自定义排序过程中，如果 compareTo 的判断条件为两个即为二次排序</p>
</li>
</ul>
<hr>
<h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><p> bean 对象实现 WritableComparable 接口重写 compareTo 方法，就可以实现自定义排序</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(FlowBean o)</span> &#123;</span><br><span class="line">    <span class="comment">// 倒序排序</span></span><br><span class="line">	<span class="keyword">return</span> <span class="built_in">this</span>.sumFlow &gt; o.sumFlow ? -<span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="Combiner"><a href="#Combiner" class="headerlink" title="Combiner"></a>Combiner</h2><h3 id="概述-3"><a href="#概述-3" class="headerlink" title="概述"></a>概述</h3><p>Combiner 是一个本地化的 reduce 操作，它是 map 运算的后续操作，主要是在 map 计算出中间文件前做一个简单的合并重复 key 值的操作</p>
<p>主要作用有：</p>
<ol>
<li>网络带宽严重被占降低程序效率，提前在 map 上执行分组，减少传输给 reduce 的数据量</li>
<li>单一节点承载过重降低程序性能，全在 reduce 上运行，导致负载过重</li>
</ol>
<p>每一个 map 都可能会产生大量的本地输出，Combiner 的作用就是对 map 端的输出先做一次合并，以减少在 map 和 reduce 节点之间的数据传输量，以提高网络 IO 性能</p>
<hr>
<h3 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h3><p>有很多人认为这个 combiner 和 map 输出的数据合并是一个过程，其实不然，map 输出的数据合并只会产生在有数据溢写的时候，即进行合并操作</p>
<p>与 mapper 和 reducer 不同的是，combiner 没有默认的实现，需要显式的设置在 conf 中才有作用。</p>
<p>并不是所有的 job 都适用 combiner，只有操作满足结合律的才可设置 combiner。combine 操作类似于：opt(opt(1, 2, 3), opt(4, 5, 6))。如果opt为求和、求最大值的话，可以使用，但是如果是求中值的话，不适用</p>
<hr>
<h3 id="自定义-combiner"><a href="#自定义-combiner" class="headerlink" title="自定义 combiner"></a>自定义 combiner</h3><p>Combiner 和 Reducer 一样，编写一个类，然后继承 Reducer，reduce 方法中写具体的 Combiner 逻辑，然后在 job 中设置 Combiner 组</p>
<p>执行后看到 map 的输出和  combine 的输入统计是一致的，而 combine 的输出与 reduce 的输入统计是一样的。由此可以看出规约操作成功，而且执行在 map 的最后，reduce 之前。</p>
<p>其实 Combiner 也可以看成就是 Reduce，俩者的代码完全一样</p>
<ol>
<li><p>Combiner 代码，将相同 key 的 value 合并</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WordCountCombiner</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, IntWritable, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="type">IntWritable</span> <span class="variable">result</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 统计当前 key 出现的次数</span></span><br><span class="line">        <span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable value : values) &#123;</span><br><span class="line">            sum += value.get();</span><br><span class="line">        &#125;</span><br><span class="line">        result.set(sum);</span><br><span class="line">        <span class="comment">// 将统计结果写入 context</span></span><br><span class="line">        context.write(key, result);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 job 中设置 combiner</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setCombinerClass(WordCountCombiner.class);</span><br></pre></td></tr></table></figure></li>
</ol>
<hr>
<h2 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h2><h3 id="Map-Join-概述"><a href="#Map-Join-概述" class="headerlink" title="Map Join 概述"></a>Map Join 概述</h3><p>如果在 Reduce 端处理过多的表，容易出现数据倾斜，通常我们会在 Map 端缓存起来，提前把处理业务逻辑，减少 Reduce 端数据的压力，减少数据倾斜。</p>
<p>Map Join 适用于一张表十分小、一张表很大的场景。</p>
<p>Mapper的setup（初始化）的时候缓存到集合中</p>
<p>map join 指的是在 MapReduce 的 map 阶段先加载一个文件缓存到内存当中，这个文件可能是从磁盘读取的或网络请求的都可以</p>
<p>map(key,value,context) 方法中读取的数据 key 和 value，这两个数据和先前缓存到内存中的数据一起做处理后再 context.write() 到 reduce 阶段</p>
<p>map join 相当于在 map 阶段写数据到 reduce 阶段前对数据做了处理</p>
<hr>
<h3 id="Map-Join-示例"><a href="#Map-Join-示例" class="headerlink" title="Map Join 示例"></a>Map Join 示例</h3><p>比如有两个 txt 文件</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 1.txt</span><br><span class="line">01 mac</span><br><span class="line">02 huawei</span><br><span class="line">03 xiaomi</span><br><span class="line"></span><br><span class="line">// 2.txt</span><br><span class="line">201801 01 1</span><br><span class="line">201802 02 2</span><br><span class="line">201803 03 3</span><br><span class="line">201804 01 4</span><br></pre></td></tr></table></figure>

<p>1.txt 第一个列代表订单id ，第二列代表商品名称</p>
<p>2.txt 第一列代表时间戳，第二列代表订单id，第三列代表数量</p>
<p>如果希望在 map 阶段输出</p>
<p>时间戳 订单id 订单数量 商品名称</p>
<p>Mapper</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 将 1.txt 加载到内存文件中，然后数据在 map 端输出数据前转换</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CacheMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, NullWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    Map&lt;String, String&gt; map = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;String, String&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将 1.txt 文件内容读取出来，放在 map 集合中</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 读取文件</span></span><br><span class="line">        <span class="type">BufferedReader</span> <span class="variable">reader</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BufferedReader</span>(<span class="keyword">new</span> <span class="title class_">InputStreamReader</span>(<span class="keyword">new</span> <span class="title class_">FileInputStream</span>(<span class="string">&quot;/1.txt&quot;</span>), <span class="string">&quot;UTF-8&quot;</span>));</span><br><span class="line">        String line;</span><br><span class="line">        <span class="comment">// 拆分数据，放入 map 集合</span></span><br><span class="line">        <span class="keyword">while</span> (StringUtils.isNotBlank(line = reader.readLine())) &#123;</span><br><span class="line">            String[] args = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">            map.put(args[<span class="number">0</span>], args[<span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * map 阶段，拆分数据，并将商品名称插入进去</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 读取数据</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line">        <span class="comment">// 拆分数据</span></span><br><span class="line">        String[] args = line.split(<span class="string">&quot; &quot;</span>);</span><br><span class="line">        <span class="comment">// 根据商品 id 查询商品名称</span></span><br><span class="line">        <span class="type">String</span> <span class="variable">id</span> <span class="operator">=</span> args[<span class="number">0</span>];</span><br><span class="line">        <span class="type">String</span> <span class="variable">name</span> <span class="operator">=</span> map.get(id);</span><br><span class="line">        <span class="comment">// 将商品名称加入进去</span></span><br><span class="line">        line = line + <span class="string">&quot; &quot;</span> + name;</span><br><span class="line">        context.write(<span class="keyword">new</span> <span class="title class_">Text</span>(line), NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<p>自定义 driver 驱动类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CacheDriver</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 创建一个 job</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration);</span><br><span class="line">        <span class="comment">// 设置 jar 包路径</span></span><br><span class="line">        job.setJarByClass(CacheDriver.class);</span><br><span class="line">        <span class="comment">// 设置 map 类和 reduce 类</span></span><br><span class="line">        job.setMapperClass(CacheMapper.class);</span><br><span class="line">        <span class="comment">// 设置输出的 key 和 value 的类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line">        <span class="comment">// 设置读取文件的路径和输出结果的文件路径</span></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;读取文件的路径&quot;</span>));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;输出文件的路径&quot;</span>));</span><br><span class="line">        <span class="comment">// 加载缓存商品数据</span></span><br><span class="line">        job.addCacheFile(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;缓存文件路径&quot;</span>));</span><br><span class="line">        <span class="comment">// 设置 reduce task 数量，因为没有设置 reduce task</span></span><br><span class="line">        job.setNumReduceTask(<span class="number">0</span>);</span><br><span class="line">        <span class="comment">// 执行 job, 传入值表示是否监控并打印 job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        <span class="comment">// 退出系统</span></span><br><span class="line">        System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<hr>
<h2 id="ETL"><a href="#ETL" class="headerlink" title="ETL"></a>ETL</h2><h3 id="什么是-ETL"><a href="#什么是-ETL" class="headerlink" title="什么是 ETL"></a>什么是 ETL</h3><p>ETL分别是“Extract”、“ Transform” 、“Load”三个单词的首字母缩写也就是“抽取”、“转换”、“装载”，但我们日常往往简称其为数据清洗</p>
<p>ETL包含了三方面：</p>
<ul>
<li>抽取：将数据从各种原始的业务系统中读取出来，这是所有工作的前提</li>
<li>转换：按照预先设计好的规则将抽取得数据进行转换，使本来异构的数据格式能统一起来。</li>
<li>装载：将转换完的数据按计划增量或全部导入到数据仓库中</li>
</ul>
<p>清理的过程往往只需要 Map 阶段而不需要 Reduce 阶段</p>
<hr>
<h3 id="ETL-示例"><a href="#ETL-示例" class="headerlink" title="ETL 示例"></a>ETL 示例</h3><p>比如有个日志文件，我们想要过滤掉其中日志长度小于 11 的内容，将其余的内容输出到文件中</p>
<p>Mapper 实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 清洗掉长度小于 11 的日志</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, IntWritable&gt; &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">IntWritable</span> <span class="variable">one</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IntWritable</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Text</span> <span class="variable">text</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();</span><br><span class="line">        <span class="comment">// ETL 清洗</span></span><br><span class="line">        <span class="keyword">if</span> (line.length() &lt; <span class="number">11</span> ) &#123;</span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125; </span><br><span class="line">        context.write(value, NullWritable.get());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<p>Driver 实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LogDrivern</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="comment">// 创建一个 job</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">configuration</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();</span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(configuration);</span><br><span class="line">        <span class="comment">// 设置 jar 包路径</span></span><br><span class="line">        job.setJarByClass(LogDriver.class);</span><br><span class="line">        <span class="comment">// 设置 map 类和 reduce 类</span></span><br><span class="line">        job.setMapperClass(WordCountMapper.class);</span><br><span class="line">        <span class="comment">// 设置输出的 key 和 value 的类型</span></span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line">        <span class="comment">// 设置读取文件的路径和输出结果的文件路径</span></span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;读取文件的路径&quot;</span>));</span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;输出文件的路径&quot;</span>));</span><br><span class="line">        <span class="comment">// 执行 job, 传入值表示是否监控并打印 job</span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">result</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">        <span class="comment">// 退出系统</span></span><br><span class="line">        System.exit(result ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


<hr>
<h2 id="MapReduce-数据压缩"><a href="#MapReduce-数据压缩" class="headerlink" title="MapReduce 数据压缩"></a>MapReduce 数据压缩</h2><h3 id="概述-4"><a href="#概述-4" class="headerlink" title="概述"></a>概述</h3><p>压缩的优缺点</p>
<p>优点：减少磁盘 IO 和存储空间</p>
<p>缺点：增加 CPU 开销</p>
<p>压缩的原则</p>
<ol>
<li>运算密集型 JOB 少用压缩</li>
<li>IO 密集型的 JOB 多用压缩</li>
</ol>
<hr>
<h3 id="MapReduce-支持的压缩编码"><a href="#MapReduce-支持的压缩编码" class="headerlink" title="MapReduce 支持的压缩编码"></a>MapReduce 支持的压缩编码</h3><table>
<thead>
<tr>
<th align="center">压缩格式</th>
<th align="center">MapReduce 自带</th>
<th align="center">算法</th>
<th align="center">文件扩展名</th>
<th align="center">是否可切片</th>
<th align="center">换成压缩格式后，原来的代码是否需要修改</th>
</tr>
</thead>
<tbody><tr>
<td align="center">DEFLATE</td>
<td align="center">是</td>
<td align="center">DEFLATE</td>
<td align="center">.deflate</td>
<td align="center">否</td>
<td align="center">不需要</td>
</tr>
<tr>
<td align="center">Gzip</td>
<td align="center">是</td>
<td align="center">DEFLATE</td>
<td align="center">.gz</td>
<td align="center">否</td>
<td align="center">不需要</td>
</tr>
<tr>
<td align="center">bzip2</td>
<td align="center">是</td>
<td align="center">bzip2</td>
<td align="center">.bz2</td>
<td align="center">是</td>
<td align="center">不需要</td>
</tr>
<tr>
<td align="center">LZ0</td>
<td align="center">否</td>
<td align="center">LZ0</td>
<td align="center">.lzo</td>
<td align="center">是</td>
<td align="center">需要建索引，还需要指定输入格式</td>
</tr>
<tr>
<td align="center">Snappy</td>
<td align="center">是</td>
<td align="center">Snappy</td>
<td align="center">.snappy</td>
<td align="center">否</td>
<td align="center">不需要</td>
</tr>
</tbody></table>
<hr>
<h3 id="压缩性能比较"><a href="#压缩性能比较" class="headerlink" title="压缩性能比较"></a>压缩性能比较</h3><table>
<thead>
<tr>
<th align="center">压缩算法</th>
<th align="center">原始文件大小</th>
<th align="center">压缩文件大小</th>
<th align="center">压缩速度</th>
<th align="center">解压速度</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Gzip</td>
<td align="center">8.3GB</td>
<td align="center">1.8GB</td>
<td align="center">17.5MB&#x2F;s</td>
<td align="center">58MB&#x2F;s</td>
</tr>
<tr>
<td align="center">bzip2</td>
<td align="center">8.3GB</td>
<td align="center">1.1GB</td>
<td align="center">2.4MB&#x2F;s</td>
<td align="center">9.5MB&#x2F;s</td>
</tr>
<tr>
<td align="center">LZ0</td>
<td align="center">8.3GB</td>
<td align="center">2.9GB</td>
<td align="center">49.3MB&#x2F;s</td>
<td align="center">74.6MB&#x2F;s</td>
</tr>
</tbody></table>
<hr>
<h3 id="数据压缩位置的选择"><a href="#数据压缩位置的选择" class="headerlink" title="数据压缩位置的选择"></a>数据压缩位置的选择</h3><p>数据压缩可以在 MapReduce 的任意阶段进行</p>
<p><img src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BMapReduce%28%E4%B8%89%29/image-20220830000501189.png" alt="image-20220830000501189"></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://yoursite.com">Simon</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://yoursite.com/2022/09/17/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%20MapReduce%20(%E4%B8%89)/">http://yoursite.com/2022/09/17/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%20MapReduce%20(%E4%B8%89)/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yoursite.com" target="_blank">Simon 的书柜</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><a class="post-meta__tags" href="/tags/MapReduce/">MapReduce</a></div><div class="post_share"><div class="social-share" data-image="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BMapReduce%28%E4%B8%89%29/F100031816.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/09/17/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%20Yarn%20(%E5%9B%9B)/" title="大数据之 Yarn (四)"><img class="cover" src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BYarn%28%E5%9B%9B%29/pexels-lukas-669612.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">大数据之 Yarn (四)</div></div></a></div><div class="next-post pull-right"><a href="/2022/05/22/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%20HDFS%20(%E4%BA%8C)/" title="大数据之 HDFS (二)"><img class="cover" src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BHDFS%28%E4%BA%8C%29/image-20220522003223149.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">大数据之 HDFS (二)</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/05/22/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%20HDFS%20(%E4%BA%8C)/" title="大数据之 HDFS (二)"><img class="cover" src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BHDFS%28%E4%BA%8C%29/image-20220522003223149.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-22</div><div class="title">大数据之 HDFS (二)</div></div></a></div><div><a href="/2022/05/22/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%20Hadoop%20%E7%AE%80%E4%BB%8B(%E4%B8%80)/" title="大数据之 Hadoop 简介(一)"><img class="cover" src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BHadoop%E7%AE%80%E4%BB%8B%28%E4%B8%80%29/image-20220522001934300.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-05-22</div><div class="title">大数据之 Hadoop 简介(一)</div></div></a></div><div><a href="/2022/09/17/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%B9%8B%20Yarn%20(%E5%9B%9B)/" title="大数据之 Yarn (四)"><img class="cover" src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8BYarn%28%E5%9B%9B%29/pexels-lukas-669612.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-17</div><div class="title">大数据之 Yarn (四)</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E8%83%8C%E6%99%AF%E5%9B%BE/v2-bd12bc8dfb61abe313ad48b907c5da94_720w.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Simon</div><div class="author-info__description">攀登亦是风景</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">41</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">32</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">8</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/CK-shadow" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:ck1996shadow@163.com" target="_blank" title="Email"><i class="fas fa-envelope-open-text"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%A7%E6%95%B0%E6%8D%AE%E8%AF%BE%E7%A8%8B%E4%B9%8B-MapReduce-%E4%B8%89"><span class="toc-number">1.</span> <span class="toc-text">大数据课程之 MapReduce (三)</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">1.1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89"><span class="toc-number">1.1.1.</span> <span class="toc-text">定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">1.1.2.</span> <span class="toc-text">优缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">1.1.3.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce-%E8%BF%9B%E7%A8%8B"><span class="toc-number">1.1.4.</span> <span class="toc-text">MapReduce 进程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E7%94%A8%E5%BA%8F%E5%88%97%E5%8C%96%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.1.5.</span> <span class="toc-text">常用序列化类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce-%E7%BC%96%E7%A8%8B%E8%A7%84%E8%8C%83"><span class="toc-number">1.1.6.</span> <span class="toc-text">MapReduce 编程规范</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#WordCount-%E6%A1%88%E4%BE%8B%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.1.7.</span> <span class="toc-text">WordCount 案例详解</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%8F%E5%88%97%E5%8C%96"><span class="toc-number">1.2.</span> <span class="toc-text">序列化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-1"><span class="toc-number">1.2.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89-bean-%E5%AF%B9%E8%B1%A1%E5%AE%9E%E7%8E%B0-Writeable-%E6%8E%A5%E5%8F%A3"><span class="toc-number">1.2.2.</span> <span class="toc-text">自定义 bean 对象实现 Writeable 接口</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A1%86%E6%9E%B6%E5%8E%9F%E7%90%86"><span class="toc-number">1.3.</span> <span class="toc-text">框架原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E7%89%87%E4%B8%8E-MapTask-%E5%B9%B6%E8%A1%8C%E5%BA%A6%E5%86%B3%E5%AE%9A%E6%9C%BA%E5%88%B6"><span class="toc-number">1.3.1.</span> <span class="toc-text">切片与 MapTask 并行度决定机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FileInputFormat-%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6"><span class="toc-number">1.3.2.</span> <span class="toc-text">FileInputFormat 切片机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce-%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B"><span class="toc-number">1.3.3.</span> <span class="toc-text">MapReduce 工作流程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Shuffle-%E6%9C%BA%E5%88%B6"><span class="toc-number">1.4.</span> <span class="toc-text">Shuffle 机制</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E4%BB%8B"><span class="toc-number">1.4.1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B"><span class="toc-number">1.4.2.</span> <span class="toc-text">详细流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%98%E8%AE%A4%E5%88%86%E5%8C%BA"><span class="toc-number">1.4.3.</span> <span class="toc-text">默认分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA"><span class="toc-number">1.4.4.</span> <span class="toc-text">自定义分区</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8E%92%E5%BA%8F"><span class="toc-number">1.5.</span> <span class="toc-text">排序</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-2"><span class="toc-number">1.5.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%B1%BB"><span class="toc-number">1.5.2.</span> <span class="toc-text">分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F"><span class="toc-number">1.5.3.</span> <span class="toc-text">实现方式</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Combiner"><span class="toc-number">1.6.</span> <span class="toc-text">Combiner</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-3"><span class="toc-number">1.6.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="toc-number">1.6.2.</span> <span class="toc-text">注意事项</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89-combiner"><span class="toc-number">1.6.3.</span> <span class="toc-text">自定义 combiner</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Join"><span class="toc-number">1.7.</span> <span class="toc-text">Join</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Map-Join-%E6%A6%82%E8%BF%B0"><span class="toc-number">1.7.1.</span> <span class="toc-text">Map Join 概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Map-Join-%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.7.2.</span> <span class="toc-text">Map Join 示例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ETL"><span class="toc-number">1.8.</span> <span class="toc-text">ETL</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF-ETL"><span class="toc-number">1.8.1.</span> <span class="toc-text">什么是 ETL</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ETL-%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.8.2.</span> <span class="toc-text">ETL 示例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce-%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9"><span class="toc-number">1.9.</span> <span class="toc-text">MapReduce 数据压缩</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0-4"><span class="toc-number">1.9.1.</span> <span class="toc-text">概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MapReduce-%E6%94%AF%E6%8C%81%E7%9A%84%E5%8E%8B%E7%BC%A9%E7%BC%96%E7%A0%81"><span class="toc-number">1.9.2.</span> <span class="toc-text">MapReduce 支持的压缩编码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8E%8B%E7%BC%A9%E6%80%A7%E8%83%BD%E6%AF%94%E8%BE%83"><span class="toc-number">1.9.3.</span> <span class="toc-text">压缩性能比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9%E4%BD%8D%E7%BD%AE%E7%9A%84%E9%80%89%E6%8B%A9"><span class="toc-number">1.9.4.</span> <span class="toc-text">数据压缩位置的选择</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/12/09/%E4%BA%91%E5%8E%9F%E7%94%9F/K8S%20%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5/" title="k8s 从入门到实践"><img src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E4%BA%91%E5%8E%9F%E7%94%9F/k8s%20%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5/preview.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="k8s 从入门到实践"/></a><div class="content"><a class="title" href="/2024/12/09/%E4%BA%91%E5%8E%9F%E7%94%9F/K8S%20%E4%BB%8E%E5%85%A5%E9%97%A8%E5%88%B0%E5%AE%9E%E8%B7%B5/" title="k8s 从入门到实践">k8s 从入门到实践</a><time datetime="2024-12-09T08:53:05.000Z" title="发表于 2024-12-09 16:53:05">2024-12-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/31/Java/Lua%20%E8%84%9A%E6%9C%AC%E5%AE%9E%E6%88%98/" title="Lua 脚本实战"><img src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/JAVA/Lua%20%E8%84%9A%E6%9C%AC%E5%AE%9E%E6%88%98/preview.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Lua 脚本实战"/></a><div class="content"><a class="title" href="/2024/10/31/Java/Lua%20%E8%84%9A%E6%9C%AC%E5%AE%9E%E6%88%98/" title="Lua 脚本实战">Lua 脚本实战</a><time datetime="2024-10-31T00:41:19.000Z" title="发表于 2024-10-31 08:41:19">2024-10-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/10/02/%E5%89%8D%E7%AB%AF/Node.js%20%E6%95%99%E7%A8%8B/" title="Node.js 教程"><img src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E5%89%8D%E7%AB%AF/Node.js%20%E6%95%99%E7%A8%8B/preview.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Node.js 教程"/></a><div class="content"><a class="title" href="/2024/10/02/%E5%89%8D%E7%AB%AF/Node.js%20%E6%95%99%E7%A8%8B/" title="Node.js 教程">Node.js 教程</a><time datetime="2024-10-02T02:06:08.000Z" title="发表于 2024-10-02 10:06:08">2024-10-02</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/09/16/Java/Spring%20Cloud%20Alibaba%20%E5%AE%9E%E6%88%98/" title="Spring Cloud Alibaba 实战"><img src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/JAVA/Spring%20Cloud%20Alibaba%20%E5%AE%9E%E6%88%98/preview.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Spring Cloud Alibaba 实战"/></a><div class="content"><a class="title" href="/2024/09/16/Java/Spring%20Cloud%20Alibaba%20%E5%AE%9E%E6%88%98/" title="Spring Cloud Alibaba 实战">Spring Cloud Alibaba 实战</a><time datetime="2024-09-16T10:10:01.000Z" title="发表于 2024-09-16 18:10:01">2024-09-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/08/10/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%BC%95%E6%93%8E%20Camunda%207/" title="工作流引擎 Camunda 7"><img src="https://simon-bookcase.oss-cn-beijing.aliyuncs.com/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%BC%95%E6%93%8E%20Camunda%207/preview.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="工作流引擎 Camunda 7"/></a><div class="content"><a class="title" href="/2024/08/10/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/%E5%B7%A5%E4%BD%9C%E6%B5%81%E5%BC%95%E6%93%8E%20Camunda%207/" title="工作流引擎 Camunda 7">工作流引擎 Camunda 7</a><time datetime="2024-08-10T04:59:43.000Z" title="发表于 2024-08-10 12:59:43">2024-08-10</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2025 By Simon</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>